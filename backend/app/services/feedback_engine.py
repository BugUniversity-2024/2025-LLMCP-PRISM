"""
Feedback Engine - è´Ÿè´£ç†è§£åé¦ˆå¹¶ç”Ÿæˆ Prompt Diff
é˜¶æ®µ 1: Mock å®ç°
é˜¶æ®µ 2: æ¥å…¥ OpenAI GPT-4o
"""
import json
import copy
import time
from pathlib import Path
from typing import Dict, Any


# Feedback System Promptï¼ˆé˜¶æ®µ 2 ä½¿ç”¨ï¼‰
FEEDBACK_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ª Prompt åé¦ˆåˆ†æå™¨ï¼Œè´Ÿè´£ç†è§£ç”¨æˆ·å¯¹å›¾ç‰‡çš„åé¦ˆï¼Œå¹¶ç”Ÿæˆç²¾ç¡®çš„ä¿®æ”¹æŒ‡ä»¤ã€‚

ã€ä»»åŠ¡ã€‘
æ ¹æ®ç”¨æˆ·åé¦ˆï¼Œç”Ÿæˆ Prompt Diff JSONï¼š
{
  "operations": [
    {"action": "add", "field": "lighting", "values": ["æ›´äº®çš„å…‰çº¿"]},
    {"action": "remove", "field": "background", "values": ["å¤æ‚èƒŒæ™¯"]},
    {"action": "adjust", "field": "weights.lighting", "delta": 0.3}
  ],
  "reasoning": "ç”¨æˆ·åé¦ˆå›¾ç‰‡å¤ªæš—ï¼Œå› æ­¤å¢åŠ lightingå­—æ®µçš„äº®åº¦æè¿°ï¼Œå¹¶æå‡æƒé‡"
}

ã€åé¦ˆæ˜ å°„è§„åˆ™ã€‘
å¸¸è§åé¦ˆç±»å‹ â†’ å¯¹åº”å­—æ®µï¼š
- "å¤ªæš—" / "å¤ªäº®" / "å…‰çº¿ä¸å¥½" â†’ lighting
- "è„¸æ€ª" / "äººç‰©å˜å½¢" / "è¡¨æƒ…ä¸å¯¹" â†’ appearance + negative
- "èƒŒæ™¯å¤ªä¹±" / "èƒŒæ™¯å¤ªç®€å•" â†’ background
- "é£æ ¼ä¸å¯¹" / "ä¸å¤Ÿå†™å®" / "å¤ªå¡é€š" â†’ style + weights
- "æ„å›¾ä¸å¥½" / "è§’åº¦ä¸å¯¹" â†’ composition
- "ä¸å¤Ÿæ¸…æ™°" / "è´¨é‡ä¸å¥½" â†’ quality

ã€æ“ä½œç±»å‹ã€‘
1. add: åœ¨æŒ‡å®šå­—æ®µæ·»åŠ æ–°çš„æè¿°å…ƒç´ 
2. remove: ä»æŒ‡å®šå­—æ®µç§»é™¤æŸäº›å…ƒç´ 
3. adjust: è°ƒæ•´ weights æƒé‡ï¼ˆdelta èŒƒå›´ -0.5 åˆ° +0.5ï¼‰
4. replace: å®Œå…¨æ›¿æ¢æŸä¸ªå­—æ®µï¼ˆæ…ç”¨ï¼‰

ã€å…³é”®åŸåˆ™ã€‘
1. æœ€å°ä¿®æ”¹ï¼šåªä¿®æ”¹ä¸åé¦ˆç›¸å…³çš„å­—æ®µ
2. ä¿æŒä¸€è‡´ï¼šä¸è¦æ”¹å˜ç”¨æˆ·æœªæåŠçš„å†…å®¹
3. å†²çªæ£€æµ‹ï¼šå¦‚æœä¿®æ”¹ä¼šå¯¼è‡´çŸ›ç›¾ï¼Œåœ¨ reasoning ä¸­è¯´æ˜
4. è§£é‡Šæ¸…æ¥šï¼šåœ¨ reasoning ä¸­è¯´æ˜ä¸ºä»€ä¹ˆè¿™æ ·ä¿®æ”¹

ã€ç¤ºä¾‹ã€‘
ç”¨æˆ·åé¦ˆï¼š"å¤ªæš—äº†"
åŸ Schema: {"lighting": ["æŸ”å’Œä¾§å…‰"], "weights": {"lighting": 0.5}}
Diff è¾“å‡º:
{
  "operations": [
    {"action": "add", "field": "lighting", "values": ["æ›´äº®çš„ç¯å¢ƒå…‰", "å¢åŠ é«˜å…‰"]},
    {"action": "adjust", "field": "weights.lighting", "delta": 0.3}
  ],
  "reasoning": "ç”¨æˆ·åé¦ˆå›¾ç‰‡å¤ªæš—ï¼Œåœ¨lightingå­—æ®µæ·»åŠ æ›´äº®çš„æè¿°ï¼Œå¹¶å°†lightingæƒé‡ä»0.5æå‡åˆ°0.8"
}
"""


class ConflictError(Exception):
    """Schema å†²çªå¼‚å¸¸"""
    pass


class FeedbackEngine:
    """åé¦ˆåˆ†æå¼•æ“ï¼ˆé˜¶æ®µ 1: Mock å®ç°ï¼‰"""

    def __init__(self, use_real_api: bool = False):
        """
        Args:
            use_real_api: æ˜¯å¦ä½¿ç”¨çœŸå® OpenAI APIï¼ˆé˜¶æ®µ 2 è®¾ç½®ä¸º Trueï¼‰
        """
        self.use_real_api = use_real_api
        if use_real_api:
            from openai import OpenAI
            from app.config import settings
            self.client = OpenAI(
                api_key=settings.openai_api_key,
                base_url=settings.openai_api_base  # æ”¯æŒè‡ªå®šä¹‰ Base URL
            )
            self.model = settings.openai_model

            # åŠ è½½ System Prompt
            self.system_prompt = self._load_system_prompt("feedback.txt")

    def _load_system_prompt(self, filename: str) -> str:
        """ä» prompts ç›®å½•åŠ è½½ System Prompt"""
        prompt_path = Path(__file__).parent.parent / "prompts" / filename
        try:
            with open(prompt_path, "r", encoding="utf-8") as f:
                return f.read()
        except FileNotFoundError:
            print(f"âš ï¸ Prompt æ–‡ä»¶æœªæ‰¾åˆ°ï¼š{prompt_path}ï¼Œä½¿ç”¨é»˜è®¤ prompt")
            return FEEDBACK_SYSTEM_PROMPT

    def analyze_feedback(
        self,
        feedback: str,
        current_schema: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        åˆ†æç”¨æˆ·åé¦ˆå¹¶ç”Ÿæˆ Prompt Diff

        Args:
            feedback: ç”¨æˆ·åé¦ˆ
            current_schema: å½“å‰ç‰ˆæœ¬çš„ Schema

        Returns:
            {
                "diff": dict,         # Prompt Diff
                "new_schema": dict,   # åº”ç”¨ Diff åçš„æ–° Schema
                "prompt": str         # æ–°çš„è‡ªç„¶è¯­è¨€ Prompt
            }

        Raises:
            ValueError: åé¦ˆä¸ºç©º
            RuntimeError: OpenAI API è°ƒç”¨å¤±è´¥
            ConflictError: Schema å†²çª
        """
        if not feedback or not feedback.strip():
            raise ValueError("ç”¨æˆ·åé¦ˆä¸èƒ½ä¸ºç©º")

        if self.use_real_api:
            return self._analyze_with_openai(feedback, current_schema)
        else:
            return self._analyze_mock(feedback, current_schema)

    def _analyze_mock(self, feedback: str, current_schema: Dict[str, Any]) -> Dict[str, Any]:
        """é˜¶æ®µ 1: Mock å®ç°"""
        # ç®€å•çš„åé¦ˆæ˜ å°„è§„åˆ™
        diff_operations = []

        if "æš—" in feedback or "äº®" in feedback:
            diff_operations.extend([
                {"action": "add", "field": "lighting", "values": ["æ›´äº®çš„ç¯å¢ƒå…‰", "å¢åŠ é«˜å…‰"]},
                {"action": "adjust", "field": "weights.lighting", "delta": 0.3}
            ])

        if "èƒŒæ™¯" in feedback:
            if "å¤æ‚" in feedback or "ä¹±" in feedback:
                diff_operations.append({
                    "action": "replace",
                    "field": "background",
                    "value": ["ç®€æ´èƒŒæ™¯", "çº¯è‰²èƒŒæ™¯"]
                })
            else:
                diff_operations.append({
                    "action": "add",
                    "field": "background",
                    "values": ["æ›´ä¸°å¯Œçš„èƒŒæ™¯ç»†èŠ‚"]
                })

        if "é£æ ¼" in feedback:
            diff_operations.extend([
                {"action": "adjust", "field": "weights.style", "delta": 0.2}
            ])

        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°è§„åˆ™ï¼Œä½¿ç”¨é»˜è®¤ä¿®æ”¹
        if not diff_operations:
            diff_operations.append({
                "action": "add",
                "field": "quality",
                "values": ["ä¼˜åŒ–ç»†èŠ‚"]
            })

        diff = {
            "operations": diff_operations,
            "reasoning": f"æ ¹æ®ç”¨æˆ·åé¦ˆã€Œ{feedback}ã€è¿›è¡Œä¼˜åŒ–è°ƒæ•´"
        }

        # åº”ç”¨ Diff
        new_schema = self._apply_diff(current_schema, diff)

        # æ¸²æŸ“æ–° Prompt
        from app.services.prompt_engine import PromptEngine
        engine = PromptEngine()
        prompt = engine._render_prompt(new_schema)

        return {
            "diff": diff,
            "new_schema": new_schema,
            "prompt": prompt
        }

    def _analyze_with_openai(
        self,
        feedback: str,
        current_schema: Dict[str, Any]
    ) -> Dict[str, Any]:
        """é˜¶æ®µ 2: çœŸå® OpenAI API è°ƒç”¨ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
        max_retries = 3
        retry_delay = 1  # ç§’

        user_prompt = f"""å½“å‰ Schema:
{json.dumps(current_schema, ensure_ascii=False, indent=2)}

ç”¨æˆ·åé¦ˆ: {feedback}

è¯·ç”Ÿæˆ Prompt Diffã€‚"""

        for attempt in range(max_retries):
            try:
                print(f"ğŸ”„ è°ƒç”¨ OpenAI API åˆ†æåé¦ˆ (å°è¯• {attempt + 1}/{max_retries})...")

                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": self.system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    response_format={"type": "json_object"},
                    temperature=0.5,
                    max_tokens=1000
                )

                diff = json.loads(response.choices[0].message.content)

                # éªŒè¯ Diff æ ¼å¼
                self._validate_diff(diff)

                # åº”ç”¨ Diff
                new_schema = self._apply_diff(current_schema, diff)

                # æ¸²æŸ“æ–° Prompt
                from app.services.prompt_engine import PromptEngine
                engine = PromptEngine()
                prompt = engine._render_prompt(new_schema)

                print(f"âœ… åé¦ˆåˆ†ææˆåŠŸ")
                return {
                    "diff": diff,
                    "new_schema": new_schema,
                    "prompt": prompt
                }

            except json.JSONDecodeError as e:
                print(f"âš ï¸ Diff è§£æå¤±è´¥: {e}")
                if attempt < max_retries - 1:
                    time.sleep(retry_delay)
                    continue
                else:
                    print(f"âŒ è§£æå¤±è´¥ï¼Œå›é€€åˆ° mock æ¨¡å¼")
                    return self._analyze_mock(feedback, current_schema)

            except Exception as e:
                print(f"âš ï¸ OpenAI API è°ƒç”¨å¤±è´¥: {e}")
                if attempt < max_retries - 1:
                    time.sleep(retry_delay)
                    retry_delay *= 2  # æŒ‡æ•°é€€é¿
                    continue
                else:
                    print(f"âŒ API è°ƒç”¨å¤±è´¥ï¼Œå›é€€åˆ° mock æ¨¡å¼")
                    return self._analyze_mock(feedback, current_schema)

    def _validate_diff(self, diff: Dict[str, Any]):
        """éªŒè¯ Diff æ ¼å¼"""
        if "operations" not in diff:
            raise ValueError("Diff ç¼ºå°‘ operations å­—æ®µ")
        if not isinstance(diff["operations"], list):
            raise ValueError("operations å¿…é¡»æ˜¯æ•°ç»„")
        if len(diff["operations"]) == 0:
            raise ValueError("operations ä¸èƒ½ä¸ºç©º")

    def _apply_diff(
        self,
        original_schema: Dict[str, Any],
        diff: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        åº”ç”¨ Prompt Diff åˆ°åŸ Schema
        """
        new_schema = copy.deepcopy(original_schema)

        for op in diff["operations"]:
            action = op["action"]
            field = op["field"]

            if action == "add":
                if field not in new_schema:
                    new_schema[field] = []
                new_schema[field].extend(op["values"])

            elif action == "remove":
                if field in new_schema and "values" in op:
                    for val in op["values"]:
                        if val in new_schema[field]:
                            new_schema[field].remove(val)

            elif action == "adjust":
                keys = field.split(".")
                current = new_schema
                for key in keys[:-1]:
                    if key not in current:
                        current[key] = {}
                    current = current[key]

                last_key = keys[-1]
                current_value = current.get(last_key, 0.5)
                new_value = current_value + op["delta"]
                current[last_key] = max(0.1, min(1.5, new_value))

            elif action == "replace":
                keys = field.split(".")
                current = new_schema
                for key in keys[:-1]:
                    current = current[key]
                current[keys[-1]] = op["value"]

        # å†²çªæ£€æµ‹
        self._detect_conflicts(new_schema)

        return new_schema

    def _detect_conflicts(self, schema: Dict[str, Any]):
        """æ£€æµ‹ Schema å†²çª"""
        style = ' '.join(schema.get("style", []))

        # å†²çªæ£€æµ‹è§„åˆ™ï¼ˆæ›´å®½æ¾ï¼‰
        conflicting_pairs = [
            (["çº¯å†™å®", "è¶…å†™å®"], ["çº¯å¡é€š", "åƒç´ é£"]),
            (["æåº¦æ˜äº®", "é«˜æ›å…‰"], ["æåº¦é»‘æš—", "çº¯é»‘èƒŒæ™¯"]),
        ]

        for group1, group2 in conflicting_pairs:
            has_group1 = any(s in style for s in group1)
            has_group2 = any(s in style for s in group2)
            if has_group1 and has_group2:
                raise ConflictError(f"Style å†²çªï¼šä¸èƒ½åŒæ—¶åŒ…å« {group1} å’Œ {group2}")

"""
Prompt Engine - è´Ÿè´£ç”Ÿæˆç»“æ„åŒ– Prompt
é˜¶æ®µ 1: Mock å®ç°
é˜¶æ®µ 2: æ¥å…¥ OpenAI GPT-4o
"""
import json
import random
import time
from pathlib import Path
from typing import Dict, Any


# System Prompt æ¨¡æ¿ï¼ˆé˜¶æ®µ 2 ä½¿ç”¨ï¼‰
GENERATION_SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ AI ç»˜ç”» Prompt ç”Ÿæˆå™¨ï¼Œä¸“é—¨ä¸ºç«å±±å¼•æ“ Seedream æ¨¡å‹ä¼˜åŒ–æç¤ºè¯ã€‚

ã€æ ¸å¿ƒè¦æ±‚ã€‘
- ç”Ÿæˆç®€æ´è¿è´¯çš„è‡ªç„¶è¯­è¨€æè¿°
- éµå¾ªç»“æ„ï¼šä¸»ä½“ + è¡Œä¸º + ç¯å¢ƒ + ç¾å­¦å…ƒç´ 
- ä½¿ç”¨ä¸­æ–‡æè¿°ï¼Œæ¯ä¸ªå…ƒç´ ç”¨çŸ­è¯­è¡¨è¾¾
- é¿å…å†—é•¿å¥å­ï¼Œä¿æŒæè¿°ç²¾ç‚¼
- æ§åˆ¶æ€»å­—æ•°åˆç†ï¼Œé¿å…ä¿¡æ¯è¿‡è½½

ã€è¾“å‡ºæ ¼å¼ã€‘
ä½ å¿…é¡»è¾“å‡º JSON æ ¼å¼ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
{
  "subject": ["ä¸»ä½“", "åŠ¨ä½œæˆ–å§¿æ€"],
  "appearance": ["å¤–è§‚ç‰¹å¾1", "å¤–è§‚ç‰¹å¾2"],
  "style": ["ç”»é£", "è‰ºæœ¯é£æ ¼"],
  "composition": ["æ„å›¾", "è§†è§’"],
  "lighting": ["å…‰ç…§", "è‰²è°ƒ"],
  "background": ["èƒŒæ™¯", "ç¯å¢ƒ"],
  "quality": ["ç”»è´¨", "åˆ†è¾¨ç‡"],
  "negative": ["é¿å…å…ƒç´ 1", "é¿å…å…ƒç´ 2"],
  "weights": {"style": 1.0, "realism": 0.7}
}

ã€å­—æ®µè¯´æ˜ã€‘
- subject: ä¸»ä½“åŠåŠ¨ä½œï¼ˆç”¨2-3ä¸ªçŸ­è¯­æè¿°æ ¸å¿ƒä¸»ä½“ï¼‰
- appearance: å¤–è§‚ç»†èŠ‚ï¼ˆ2-4ä¸ªå…³é”®è§†è§‰ç‰¹å¾ï¼‰
- style: ç”»é£é£æ ¼ï¼ˆå¦‚ï¼šåŠå†™å®ã€åŠ¨æ¼«é£ã€ç”µå½±æ„Ÿï¼‰
- composition: æ„å›¾è§†è§’ï¼ˆå¦‚ï¼šç‰¹å†™ã€ä¿¯è§†ã€ä¸‰åˆ†æ³•ï¼‰
- lighting: å…‰ç…§è‰²è°ƒï¼ˆå¦‚ï¼šæŸ”å…‰ã€æš–è‰²è°ƒã€é€†å…‰ï¼‰
- background: èƒŒæ™¯ç¯å¢ƒï¼ˆç®€æ´æè¿°ï¼Œ2-3ä¸ªå…ƒç´ ï¼‰
- quality: ç”»è´¨è¦æ±‚ï¼ˆå¦‚ï¼šé«˜æ¸…ã€ç»†èŠ‚ä¸°å¯Œã€2Kï¼‰
- negative: è´Ÿé¢æç¤ºï¼ˆå¸¸è§è´¨é‡é—®é¢˜ï¼‰
- weights: æƒé‡ï¼ˆstyle: é£æ ¼å¼ºåº¦, realism: å†™å®åº¦ï¼ŒèŒƒå›´ 0.1-1.5ï¼‰

ã€å‚è€ƒæ¡ˆä¾‹ 1ã€‘
ç”¨æˆ·è¾“å…¥ï¼š"ä¸€åªæ©˜çŒ«åœ¨çª—è¾¹æ™’å¤ªé˜³"
è¾“å‡ºï¼š
{
  "subject": ["æ©˜çŒ«", "æ…µæ‡’è¶´ç€"],
  "appearance": ["æ©˜è‰²çŸ­æ¯›", "ç»¿è‰²çœ¼ç›", "è“¬æ¾å°¾å·´"],
  "style": ["åŠå†™å®é£æ ¼", "æ¸©æš–è‰²è°ƒ"],
  "composition": ["ç‰¹å†™é•œå¤´", "æµ…æ™¯æ·±"],
  "lighting": ["æ¸©æš–åˆåé˜³å…‰", "æŸ”å’Œä¾§å…‰"],
  "background": ["æœ¨è´¨çª—å°", "çª—å¤–æ ‘å½±"],
  "quality": ["é«˜æ¸…", "ç»†èŠ‚ä¸°å¯Œ"],
  "negative": ["æ¨¡ç³Š", "å˜å½¢", "å¤šä½™è‚¢ä½“"],
  "weights": {"style": 1.0, "realism": 0.8}
}

ã€å‚è€ƒæ¡ˆä¾‹ 2ã€‘
ç”¨æˆ·è¾“å…¥ï¼š"ç§‘å¹»åŸå¸‚å¤œæ™¯"
è¾“å‡ºï¼š
{
  "subject": ["æœªæ¥åŸå¸‚", "é«˜è€¸æ‘©å¤©å¤§æ¥¼"],
  "appearance": ["ç»ç’ƒå¹•å¢™", "éœ“è™¹ç¯å…‰", "é£è¡Œå™¨"],
  "style": ["èµ›åšæœ‹å…‹", "ç§‘å¹»æ„Ÿ"],
  "composition": ["å¹¿è§’", "ä»°è§†"],
  "lighting": ["éœ“è™¹å†·å…‰", "ç´«è“è‰²è°ƒ", "å…‰çº¿è¿½è¸ª"],
  "background": ["å¤œç©º", "ç¹æ˜Ÿ", "å…‰æ±¡æŸ“"],
  "quality": ["4K", "ç”µå½±çº§"],
  "negative": ["æ¨¡ç³Š", "ä½æ¸…", "å™ªç‚¹"],
  "weights": {"style": 1.3, "realism": 0.6}
}

ã€ç”Ÿæˆè§„åˆ™ã€‘
1. æ¯ä¸ªæ•°ç»„æä¾› 2-4 ä¸ªç®€çŸ­å…ƒç´ ï¼ˆé¿å…å•ä¸ªå…ƒç´ è¿‡é•¿ï¼‰
2. ä½¿ç”¨ä¸“ä¸šç»˜ç”»æœ¯è¯­å’Œè§†è§‰æè¿°
3. ä¼˜å…ˆæè¿°è§†è§‰å¯è§çš„å…ƒç´ 
4. é¿å…æŠ½è±¡æ¦‚å¿µï¼Œèšç„¦å…·ä½“ç”»é¢
5. negative åˆ—å‡ºå¸¸è§è´¨é‡é—®é¢˜
6. ç¡®ä¿ JSON æ ¼å¼æ­£ç¡®
"""


class PromptEngine:
    """Prompt ç”Ÿæˆå¼•æ“ï¼ˆé˜¶æ®µ 1: Mock å®ç°ï¼‰"""

    def __init__(self, use_real_api: bool = False):
        """
        Args:
            use_real_api: æ˜¯å¦ä½¿ç”¨çœŸå® OpenAI APIï¼ˆé˜¶æ®µ 2 è®¾ç½®ä¸º Trueï¼‰
        """
        self.use_real_api = use_real_api
        if use_real_api:
            from openai import OpenAI
            from app.config import settings
            self.client = OpenAI(
                api_key=settings.openai_api_key,
                base_url=settings.openai_api_base  # æ”¯æŒè‡ªå®šä¹‰ Base URL
            )
            self.model = settings.openai_model

        # åŠ è½½ System Promptï¼ˆå¦‚æœä½¿ç”¨çœŸå® APIï¼‰
        if use_real_api:
            self.system_prompt = self._load_system_prompt("generation.txt")

    def _load_system_prompt(self, filename: str) -> str:
        """ä» prompts ç›®å½•åŠ è½½ System Prompt"""
        prompt_path = Path(__file__).parent.parent / "prompts" / filename
        try:
            with open(prompt_path, "r", encoding="utf-8") as f:
                return f.read()
        except FileNotFoundError:
            print(f"âš ï¸ Prompt æ–‡ä»¶æœªæ‰¾åˆ°ï¼š{prompt_path}ï¼Œä½¿ç”¨é»˜è®¤ prompt")
            return GENERATION_SYSTEM_PROMPT

    def generate_schema(self, user_input: str) -> Dict[str, Any]:
        """
        æ ¹æ®ç”¨æˆ·è¾“å…¥ç”Ÿæˆç»“æ„åŒ– Schema

        Args:
            user_input: ç”¨æˆ·çš„åˆ›æ„æè¿°

        Returns:
            {
                "schema": dict,  # ç»“æ„åŒ– Schema
                "prompt": str    # è‡ªç„¶è¯­è¨€ Prompt
            }

        Raises:
            ValueError: ç”¨æˆ·è¾“å…¥ä¸ºç©º
            RuntimeError: OpenAI API è°ƒç”¨å¤±è´¥
        """
        if not user_input or not user_input.strip():
            raise ValueError("ç”¨æˆ·è¾“å…¥ä¸èƒ½ä¸ºç©º")

        if self.use_real_api:
            return self._generate_with_openai(user_input)
        else:
            return self._generate_mock(user_input)

    def _generate_mock(self, user_input: str) -> Dict[str, Any]:
        """é˜¶æ®µ 1: Mock å®ç°"""
        # é¢„è®¾çš„ä¸¤ä¸ª Schema æ¨¡æ¿
        templates = [
            {
                "subject": ["ä¸€åªæ©˜çŒ«", "åå§¿"],
                "appearance": ["æ©˜è‰²æ¯›å‘", "è“è‰²çœ¼ç›", "è“¬æ¾å°¾å·´"],
                "style": ["åŠå†™å®", "åŠ¨æ¼«é£æ ¼", "æŸ”å’Œçº¿æ¡"],
                "composition": ["ç‰¹å†™", "æµ…æ™¯æ·±", "æ­£é¢è§†è§’"],
                "lighting": ["æŸ”å’Œä¾§å…‰", "æš–è‰²è°ƒ", "æ—¥è½å…‰"],
                "background": ["çª—è¾¹", "æ—¥è½", "æœ¦èƒ§èƒŒæ™¯"],
                "quality": ["é«˜æ¸…", "ç»†èŠ‚ä¸°å¯Œ", "16:9"],
                "negative": ["æ¨¡ç³Š", "å˜å½¢", "å¤šä½™è‚¢ä½“"],
                "weights": {"style": 1.0, "realism": 0.7}
            },
            {
                "subject": ["ä¸‰ä½è§’è‰²", "å¤´å¯¹å¤´èººåœ¨è‰åœ°"],
                "appearance": ["é¢éƒ¨æ¸…æ™°", "æœè£…è‡ªç„¶", "å¤´å‘éšé£æ•£å¼€"],
                "style": ["äºŒæ¬¡å…ƒåŠå†™å®", "æ˜æ˜¾çº¿æ¡æ„Ÿ", "çœŸå®å…‰å½±"],
                "composition": ["ä¿¯æ‹70åº¦", "åœ†å½¢æ„å›¾", "å¤´éƒ¨å±…ä¸­"],
                "lighting": ["æ¸©æš–åˆåå…‰", "ä¾§é€†å…‰", "æŸ”å’Œé«˜å…‰"],
                "background": ["ç§‹å¤©è‰åœ°", "é»„ç»¿è¤è‰²", "è½å¶é£˜è½"],
                "quality": ["16:9", "1920x1080", "é«˜æ¸…ç»†è…»"],
                "negative": ["æ¨¡ç³Š", "å˜å½¢", "è¿‡åº¦æ‰å¹³"],
                "weights": {"style": 1.0, "realism": 0.8}
            }
        ]

        # éšæœºé€‰æ‹©ä¸€ä¸ªæ¨¡æ¿
        schema = random.choice(templates)

        # æ¸²æŸ“ä¸º Prompt
        prompt = self._render_prompt(schema)

        return {
            "schema": schema,
            "prompt": prompt
        }

    def _generate_with_openai(self, user_input: str) -> Dict[str, Any]:
        """é˜¶æ®µ 2: çœŸå® OpenAI API è°ƒç”¨ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
        max_retries = 3
        retry_delay = 1  # ç§’

        for attempt in range(max_retries):
            try:
                print(f"ğŸ”„ è°ƒç”¨ OpenAI API (å°è¯• {attempt + 1}/{max_retries})...")

                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": self.system_prompt},
                        {"role": "user", "content": user_input}
                    ],
                    response_format={"type": "json_object"},
                    temperature=0.7,
                    max_tokens=1500
                )

                schema_json = json.loads(response.choices[0].message.content)

                # éªŒè¯ Schema å®Œæ•´æ€§
                self._validate_schema(schema_json)

                prompt = self._render_prompt(schema_json)

                print(f"âœ… Prompt ç”ŸæˆæˆåŠŸ")
                return {
                    "schema": schema_json,
                    "prompt": prompt
                }

            except json.JSONDecodeError as e:
                print(f"âš ï¸ Schema è§£æå¤±è´¥: {e}")
                if attempt < max_retries - 1:
                    time.sleep(retry_delay)
                    continue
                else:
                    print(f"âŒ è§£æå¤±è´¥ï¼Œå›é€€åˆ° mock æ¨¡å¼")
                    return self._generate_mock(user_input)

            except Exception as e:
                print(f"âš ï¸ OpenAI API è°ƒç”¨å¤±è´¥: {e}")
                if attempt < max_retries - 1:
                    time.sleep(retry_delay)
                    retry_delay *= 2  # æŒ‡æ•°é€€é¿
                    continue
                else:
                    print(f"âŒ API è°ƒç”¨å¤±è´¥ï¼Œå›é€€åˆ° mock æ¨¡å¼")
                    return self._generate_mock(user_input)

    def _validate_schema(self, schema: Dict[str, Any]):
        """éªŒè¯ Schema å®Œæ•´æ€§"""
        required_fields = [
            "subject", "appearance", "style", "composition",
            "lighting", "background", "quality", "negative", "weights"
        ]
        for field in required_fields:
            if field not in schema:
                raise ValueError(f"Schema ç¼ºå°‘å¿…è¦å­—æ®µï¼š{field}")

    def _render_prompt(self, schema: Dict[str, Any]) -> str:
        """
        å°† Schema æ¸²æŸ“ä¸ºè‡ªç„¶è¯­è¨€ Prompt

        éµå¾ªç«å±±å¼•æ“æ¨èé£æ ¼ï¼š
        - ç®€æ´è¿è´¯çš„è‡ªç„¶è¯­è¨€æè¿°
        - ä¸»ä½“ + è¡Œä¸º + ç¯å¢ƒ + ç¾å­¦å…ƒç´ 
        - æ§åˆ¶åœ¨ 300 å­—ä»¥å†…
        """
        parts = []

        # 1. ä¸»ä½“åœºæ™¯ï¼ˆæ ¸å¿ƒï¼‰
        subject_parts = []
        if schema.get("subject"):
            subject_parts.extend(schema["subject"])
        if schema.get("appearance"):
            subject_parts.extend(schema["appearance"])

        if subject_parts:
            parts.append('ï¼Œ'.join(subject_parts))

        # 2. æ„å›¾ä¸è§†è§’
        if schema.get("composition"):
            parts.append('ï¼Œ'.join(schema["composition"]))

        # 3. å…‰ç…§ä¸æ°›å›´
        if schema.get("lighting"):
            parts.append('ï¼Œ'.join(schema["lighting"]))

        # 4. èƒŒæ™¯ç¯å¢ƒ
        if schema.get("background"):
            parts.append('ï¼Œ'.join(schema["background"]))

        # 5. é£æ ¼ä¸è´¨é‡
        style_parts = []
        if schema.get("style"):
            style_parts.extend(schema["style"])
        if schema.get("quality"):
            style_parts.extend(schema["quality"])

        if style_parts:
            parts.append('ï¼Œ'.join(style_parts))

        # ä¸»è¦æè¿°ï¼ˆè‡ªç„¶æµç•…çš„å¥å­ï¼‰
        main_prompt = 'ï¼Œ'.join(parts)

        # è´Ÿé¢æç¤ºï¼ˆå•ç‹¬ä¸€è¡Œï¼Œä¿æŒæ¸…æ™°ï¼‰
        negative_prompt = ""
        if schema.get("negative"):
            negative_prompt = f"\nè´Ÿé¢æç¤ºï¼š{', '.join(schema['negative'])}"

        return main_prompt + negative_prompt
